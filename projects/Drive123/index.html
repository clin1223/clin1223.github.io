<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Drive-1-to-3: Enriching Diffusion Priors for Novel View Synthesis of Real Vehicles</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="logo">
              <a href="index.html">
                <!-- <img src="./assets/images/propainter_logo1" width=200px alt="Logo"> -->
                <img src="static/images/logo.png"  width="125" height="125"  onmouseover="this.src='static/images/logo1.png';" onmouseout="this.src='static/images/logo.png';">
              </a>
              </div>
              <br>
            <h1 class="title is-1 publication-title">Drive-1-to-3: Enriching Diffusion Priors for Novel View Synthesis
              of Real Vehicles</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://clin1223.github.io" target="_blank">Chuang Lin<sup>1</sup></a>&nbsp;&nbsp;</span>
                <span class="author-block">
                  <a href="https://bbzh.github.io" target="_blank">Bingbing Zhuang<sup>4</sup></a>&nbsp;&nbsp;</span>
                  <span class="author-block">
                    <a href="https://siwensun.github.io" target="_blank">Shanlin Sun<sup>2</sup></a>&nbsp;&nbsp;</span>
                    <span class="author-block">
                      <a href="https://geekjzy.github.io" target="_blank">Ziyu Jiang<sup>4</sup></a>&nbsp;&nbsp;</span><br>
                      <span class="author-block">
                        <a href="https://jianfei-cai.github.io" target="_blank">Jianfei Cai<sup>1</sup></a>&nbsp;&nbsp;</span>
                        <span class="author-block">
                          <a href="https://cseweb.ucsd.edu/~mkchandraker/" target="_blank">Manmohan Chandraker<sup>3,4</sup></a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <p><sup>1</sup>Monash University</a>&nbsp;&nbsp;&nbsp;
                      <sup>2</sup>UC Irvine</a>&nbsp;&nbsp;&nbsp;
                      <sup>3</sup>UC San Diego</a>&nbsp;&nbsp;&nbsp;
                      <sup>4</sup>NEC Labs America</a>&nbsp;&nbsp;&nbsp;
                    </p>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2412.14494v1" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://arxiv.org/pdf/2412.14494v1" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.14494" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/video_teaser.mp4"
        type="video/mp4">
      </video>
      <!-- <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2> -->
    </div>
  </div>
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       <div class="item">
        <div class="content has-text-centered" style="width: 100%; height: auto;">
        <p>
        <strong>Drive-1-to-3</strong> studys good practices to leverage rich priors in large pretrained diffusion models towards novel view synthesis for real vehicles. 
        </p>
      </div>
    </div>
    </div>
    </div>
  </div>
</div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The recent advent of large-scale 3D data, e.g. Objaverse, has led to impressive progress in training pose-
            conditioned diffusion models for novel view synthesis. However, due to the synthetic nature of such 3D data, their performance drops significantly when applied to real-world images. This paper consolidates a set of good practices to
            finetune large pretrained models for a real-world task – harvesting vehicle assets for autonomous driving applications. To this end, we delve into the discrepancies between
            the synthetic data and real driving data, then develop several strategies to account for them properly. Specifically,
            we start with a virtual camera rotation of real images to
            ensure geometric alignment with synthetic data and consistency with the pose manifold defined by pretrained models.
            We also identify important design choices in object-centric
            data curation to account for varying object distances in real
            driving scenes – learn across varying object scales with
            fixed camera focal length. Further, we perform occlusion-aware training in latent spaces to account for ubiquitous
            occlusions in real data, and handle large viewpoint changes
            by leveraging a symmetric prior. Our insights lead to effective finetuning that results in a 68.8% reduction in FID for
            novel view synthesis over prior arts.
          </p>
        </div>
      </div>
    </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       <div class="item">
        <div class="content has-text-left" style="width: 100%; height: auto;">
        <h2 class="title is-3">Pipeline</h2>
        <p>
          The overall pipeline of Drive-1-to-3. First, it processes a single vehicle image from on-board cameras, virtually rotating it to
          a shared orbital pose. The object-centric image cropped with a constant focal length is fed to a pose-conditioned diffusion model, which
          performs occlusion-aware training in latent space with a symmetric prior.
        </p>
        <img src="static/images/pipeline.jpg" alt="MY ALT TEXT" style="width: 100%; height: auto; margin-bottom: 3em"/>
      </div>
    </div>
    </div>
    </div>
  </div>
</div>
</section>

<style>
  ul.custom-list {
    list-style-type: none; /* 去掉默认的项目符号 */
    padding: 0;
  }
  
  ul.custom-list li {
    background-image: url('static/images/car2.png'); /* 替换为你的图标的路径 */
    background-repeat: no-repeat;
    background-position: left center;
    background-size: 30px 30px;
    padding-left: 40px; /* 根据图标大小调整 */
    line-height: 30px; /* 根据需要调整行高以垂直居中文本 */
  }
  </style>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       <div class="item">
        <div class="content has-text-left" style="width: 100%; height: auto;">
        <h2 class="title is-3">Novel View Synthesis</h2>
        <ul class="custom-list">
          <li> Geometrically Consistent: Project real camera poses into object-centric orbital camera poses.</li>
          <li> Constant Focal Length: Handle large variations in camera-to-object distances in real data.</li>
          <li> Occlusion-aware Training: Convert the occlusion mask to the latent space. </li>
          <li> Viewpoint Change: Enlarge the pose variations in training data by leveraging a left-right symmetric prior for vehicle categories.</li>
        </ul>
        <p style="padding-left: 40px">
          Comparisons between the pretrained Free3D and ours on real vehicle images, demonstrating our large performance gain.
        </p>
      </div>
    </div>
    </div>
    </div>
  </div>
</div>
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-centered is-three-fifths">
       <div class="item">
        <img src="static/images/teaser.png" alt="MY ALT TEXT"/>
      </div>
    </div>
  </div>
</div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       <div class="item">
        <div class="content has-text-left" style="width: 100%; height: auto;">
        <h2 class="title is-3">3D Reconstruction with LGM</h2>
      </div>
    </div>
    </div>
    </div>
  </div>
</div>
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-centered is-three-fifths">
       <div class="item">
        <img src="static/images/lgm.jpg" alt="MY ALT TEXT" style="margin-top: -2em"/>
      </div>
    </div>
  </div>
</div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       <div class="item">
        <div class="content has-text-left" style="width: 100%; height: auto;">
        <h2 class="title is-3">Application for Object Insertion</h2>
        <p>
          We demonstrate the application in virtual object insertion, by integrating the 3D object model from Drive-1-to-3+LGM output into Unisim, a NeRF simulator for dynamic driving scenes.
          </p>
      </div>
    </div>
    </div>
    </div>
  </div>
</div>
<div class="container is-max-desktop">
  <div class="hero-body">
    <video poster="" id="tree" autoplay controls muted loop height="100%" style="margin-top: -2em">
      <!-- Your video here -->
      <source src="static/videos/drive123.mp4"
      type="video/mp4">
    </video>
    <!-- <h2 class="subtitle has-text-centered">
      Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
    </h2> -->
  </div>
</div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
       <div class="item">
        <div class="content has-text-left" style="width: 100%; height: auto;">
        <h2 class="title is-3">More Results</h2>
        <p>
          <strong>Challenging cases:</strong> results on night-time condition, unusual vehicle, and strong surface reflection; <strong>Cross-dataset generalization:</strong> results on the low-resolution NuScenes images
          and high-resolution DVM-Car images.
        </p>
      </div>
    </div>
    </div>
    </div>
  </div>
</div>
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-centered is-three-fifths">
       <div class="item">
        <img src="static/images/more_results.jpg" alt="MY ALT TEXT" style="margin-top: -2em"/>
      </div>
    </div>
  </div>
</div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{lin2024drive1to3enrichingdiffusionpriors,
        title={Drive-1-to-3: Enriching Diffusion Priors for Novel View Synthesis of Real Vehicles}, 
        author={Chuang Lin and Bingbing Zhuang and Shanlin Sun and Ziyu Jiang and Jianfei Cai and Manmohan Chandraker},
        year={2024},
        url={https://arxiv.org/abs/2412.14494}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
